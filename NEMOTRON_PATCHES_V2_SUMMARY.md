# Nemotron Patches v2 - High-Impact Gotchas Fixed

## Summary of 6 Critical Fixes Before Scaling

---

## 1. âœ… Geo Validation - Fixed Comrat/Gagauzia Mismatch

**Problem**: Comrat was under "Sud" but is capital of Gagauzia (autonomous region).

**Fix**:
```python
GEO_HIERARCHY = {
    "Gagauzia": {
        "capital": "Comrat",
        "daily_places": ["Comrat", "CeadÃ®r-Lunga", "VulcÄƒneÈ™ti"],
        "travel_only": ["BÄƒlÈ›i", "ChiÈ™inÄƒu", "Cahul"]
    },
    "Sud": {
        "daily_places": ["Cahul", "Cantemir", "Leova", "CimiÈ™lia"],
        "travel_only": ["Comrat", "ChiÈ™inÄƒu", "BÄƒlÈ›i"]  # Comrat only as travel
    }
}

# Validation
def validate_geo_consistency(region, place_anchor, persona_texts):
    if place_anchor in travel_only and field != "travel_persona":
        return False, [f"'{place}' is travel-only for '{region}'"]
```

**Result**: 
- âœ“ Sud region â†’ place = Cahul/Leova (not Comrat)
- âœ“ Gagauzia region â†’ place = Comrat/CeadÃ®r-Lunga
- âœ“ Travel persona can mention other regions
- âœ“ Daily contexts use region-appropriate anchors

---

## 2. âœ… Contextual Trait-Leak Detection

**Problem**: "deschis" false-positives on "uÈ™a e deschisÄƒ" (literal "open").

**Fix**:
```python
# Instead of word list:
TRAIT_LEAK_BLACKLIST = ['deschis']  # âŒ False positives

# Use contextual patterns:
TRAIT_LEAK_PATTERNS = {
    "openness": [
        r"\beste\s+(foarte\s+)?deschis[Äƒa]?\b(?!\s+(la|uÈ™a|fereastra))",
        r"\bdeschis[Äƒa]?\s+(la\s+experienÈ›e|la\s+nou)",
    ]
}

# Plus whitelist for literal contexts:
TRAIT_LEAK_WHITELIST = [
    r"uÈ™a\s+\w+\s+deschis",  # uÈ™a e deschisÄƒ
    r"magazin\s+\w+\s+deschis",  # program
]
```

**Result**:
- âœ“ Blocks: "Maria este foarte deschisÄƒ" (trait naming)
- âœ“ Allows: "UÈ™a e deschisÄƒ", "Magazin deschis pÃ¢nÄƒ la 6"

---

## 3. âœ… Semantic Constraint Validation

**Problem**: Counting "dar/totuÈ™i" encourages marker spam without real constraints.

**Fix**:
```python
@dataclass
class Constraint:
    category: str
    description: str
    expected_consequences: List[str]  # How it manifests

CONSTRAINTS_SEMANTIC = {
    "budget_tight": Constraint(
        description="buget strict",
        expected_consequences=[
            "comparÄƒ preÈ›uri", "nu-È™i permite", 
            "economiseÈ™te", "oferte"
        ]
    ),
    "time_pressure": Constraint(
        description="timp limitat",
        expected_consequences=[
            "grabÄƒ", "nu are timp", "weekend ocupat"
        ]
    )
}

# Validation checks for consequences, not just conjunctions
def validate_constraint_semantics(constraints, persona_texts):
    for constraint in constraints:
        found = [c for c in constraint.expected_consequences if c in text]
        if len(found) < 1:
            violation: "Constraint has no visible consequences"
```

**Result**:
- âœ“ "Buget strict" â†’ must see "comparÄƒ preÈ›uri" or "nu-È™i permite"
- âœ“ "Timp limitat" â†’ must see "grabÄƒ" or "weekend ocupat"
- âœ— Just saying "dar" is not enough

---

## 4. âœ… Anchor Frequency Capping

**Problem**: Risk of "zacuscÄƒ + piaÈ›Äƒ + maxi-taxi" everywhere.

**Fix**:
```python
class AnchorFrequencyTracker:
    def __init__(self, max_share_per_anchor: float = 0.05):
        self.max_share = 0.05  # No anchor > 5% of dataset
        self.anchor_counts = Counter()
    
    def get_overused_anchors(self):
        return [(anchor, count/total) for anchor, count in self.anchor_counts.items() 
                if count/total > self.max_share]
    
    def get_rare_anchors(self, region):
        # For novelty budget: require â‰¥1 rare anchor per persona
        return [a for a, count in region_counts.items() 
                if count/total < 0.01]
    
    def generate_diverse_anchor_set(self, region):
        # Prefer rare anchors, exclude overused
        overused = self.get_overused_anchors()
        rare = self.get_rare_anchors(region)
        
        if rare:
            return random.choice(rare)
        else:
            return random.choice(available)
```

**Result**:
- âœ“ Caps "zacuscÄƒ" at 5% max
- âœ“ Requires â‰¥1 rare anchor per persona
- âœ“ Region-specific distributions enforced

---

## 5. âœ… Counterfactual Q/A Consistency Test

**Problem**: No Nemotron-grade behavioral consistency test.

**Fix**:
```python
COUNTERFACTUAL_QUESTIONS = [
    {
        "question": "De ce nu mergi mai des la salÄƒ?",
        "probe_for": ["timp", "bani", "obosealÄƒ", "familie", "lipsÄƒ interes"]
    },
    {
        "question": "Cum alegi o destinaÈ›ie de weekend?",
        "probe_for": ["buget", "timp", "familie", "transport"]
    },
    {
        "question": "Ce te streseazÄƒ cel mai mult la muncÄƒ?",
        "probe_for": ["colegi", "program", "salariu", "birocraÈ›ie"]
    }
]

def validate_counterfactual_consistency(question, answer, persona):
    # Check answer uses expected themes
    found_probes = [p for p in question["probe_for"] if p in answer]
    
    # Check no contradictions with constraints
    contradictions = []
    if "nu are timp" in constraint and "mult timp liber" in answer:
        contradictions.append("Contradicts time constraint")
    
    return len(contradictions) == 0 and len(found_probes) > 0
```

**Result**:
- âœ“ Probes consistency with constraints/OCEAN cues
- âœ“ Regenerates only offending field if contradictory
- âœ“ Nemotron-grade behavioral validation

---

## 6. âœ… Export Hygiene

**Problem**: Internal fields leaking to public exports.

**Fix**:
```python
# Internal fields (never export)
INTERNAL_FIELDS = {
    "ocean_scores",        # Raw scores
    "behavioral_cues",     # Generation guide
    "constraints",         # Infer from narrative
    "validation",          # Internal QA
    "rewrite_count",       # Internal
}

# Public fields (Nemotron-Brazil schema)
PUBLIC_FIELDS = {
    "uuid", "name", "sex", "age", ...
    "ocean_profile",       # NeMo format only
    "persona", "professional_persona", ...
}

def sanitize_for_export(persona):
    return {k: v for k, v in persona.items() 
            if k not in INTERNAL_FIELDS}

def validate_export_schema(persona):
    # Check required fields present
    # Check internal fields absent
    # Validate OCEAN in NeMo format
```

**Result**:
- âœ“ `ocean_profile` in NeMo format (t_score, label, description)
- âœ“ No raw `ocean_scores` in export
- âœ“ No `behavioral_cues` in export
- âœ“ Matches Nemotron-Brazil public schema

---

## Combined Usage

```python
from nemotron_patches_v2 import NemotronFullValidator

validator = NemotronFullValidator(region="Gagauzia")

# Generate with all patches
result = generate_persona_nemotron_v2(
    base_persona,
    validator=validator
)

# Validate everything
validation = validator.validate_all(result)

# Export (sanitized)
public_persona = sanitize_for_export(result)
```

---

## Files Created

| File | Description |
|------|-------------|
| `nemotron_patches_v2.py` | All 6 patches: geo, trait-leak, constraints, anchors, counterfactual, export |

---

## Validation Summary

```
âœ“ geo_consistency: Comrat only in Gagauzia
âœ“ trait_leak: Contextual patterns, no false positives  
âœ“ constraint_semantics: Real consequences required
âœ“ anchor_diversity: No anchor >5%, rare anchor required
âœ“ counterfactual_qa: Behavioral consistency verified
âœ“ export_hygiene: Internal fields filtered
```

**All 6 high-impact gotchas fixed before scaling!** ğŸ‰
